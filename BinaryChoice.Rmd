---
title: "Binary Choice Models"
author: "Jerome Dumortier"
date: "`r format(Sys.time(),'%d %B %Y')`"
output: 
     beamer_presentation:
          theme: "Hannover"
          slide_level: 3
section-titles: false
classoption: "aspectratio=169"
linkcolor: MidnightBlue
---

```{r,echo=FALSE,warning=FALSE,message=FALSE,error=FALSE}
library(ggplot2)
library(reshape2)
load("D:/Teaching/Data Analysis for Public Affairs/Data/DataAnalysisPAData.RData")
```

### Overview
Binary choice models and possible research questions

- Did you vote during the last election?
- Does an individual get arrested after being released from prison?
- Does an individual participate in the labor market?

Dependent variable $y$ takes on one of two values: 0 or 1

# Numerical Methods
### Example
Consider the following equations

$$
\begin{aligned}
     y &=x^2\\
     y &=x^2+\sqrt{x}
\end{aligned}
$$

Questions

- What is the value of $y$ if $x=4$ or $x=9$?
- What is the value of $x$ if $y=81$ or $x=14$? 

Need for numerical methods to determine the answer to the last question more generally for the second equation

# Theoretical Concepts
### Sample Binary Choice Data from the GSS
```{r,echo=FALSE,fig.dim=c(5,3)}
df        = subset(gss,year==2022 & owngun %in% c(1,2) & vote20 %in% c(1,2),select=c("age","owngun","vote20"))
df        = na.omit(df)
df$owngun = ifelse(df$owngun==1,1,0)
df$vote20 = ifelse(df$owngun==1,1,0)
df        = melt(df,id=c("age"))
df        = df[sample(nrow(df),100),]
ggplot(df,aes(x=age,y=value))+geom_point()+facet_wrap(vars(variable))+theme_bw()+
     xlab("Age")+ylab("Outcome")
```

### Linear Probability Model (LPM)
Most rudimentary model for binary choice

- Use of linear regression model, i.e., $y_i=\beta_0+\beta_1 \cdot x_i+\epsilon$

Problems

- Possibility of $E(y_i|x_i)>1$ or $E(y_i|x_i)<0$
- Error terms are neither normally distributed nor homoscedastic

Alternative: Logit and Probit

- Calculation of the probability that the outcome equals 1 given exogenous variables, i.e, $Pr(y=1|x)$

### Common Setup for Logit and Probit Models
General assumption about some function $G(\cdot)$ for all values of $z$
$$0 \leq G(z) \leq 1$$
Let
$$z=\beta_0+\beta_1 \cdot x_1+\cdots+\beta_k \cdot x_k$$
Then, we have
$$P(y=1|x)=G(\beta_0+\beta_1 \cdot x_1 + \cdots + \beta_k \cdot x_k)$$

### Logit Model
Remember the Bernoulli distribution from statistics:
$$
\begin{aligned}
     Pr(y=1) &=p\\
     Pr(y=0) &=1-p
\end{aligned}
$$
with $E(y)=p$. Use of the cumulative logistic distribution function leading to the following for the logit model
$$Pr(y=1)=G(z)=\frac{e^z}{1+e^z}=\frac{1}{1+e^{-z}}$$
where $z=\beta_0+\beta_1 \cdot x_1+\cdots+\beta_k \cdot x_k$

### Probit Model
Instead of using the cumulative logistic distribution, the probit model uses the cumulative normal distribution:
$$G(z)=\Phi(z)$$
Both models lead to similar results (not similar coefficients) and are solved using so-called maximum likelihood estimation (MLE)

## Example using `organic`
Data description
        
- $income$ of the respondent in \$ 1,000
- $buying$ of organic food: yes (1) or no (0)
        
Results of interest for the binary choice model (for other models as well)
        
- Coefficient estimates
- Marginal effects
- Predicted probabilities

Notes

- Estimation through Maximum Likelihood
- Difficulty interpreting the values of coefficient

## Comparison LPM vs. Logit
```{r,echo=FALSE,fig.width=10,fig.height=5}
income              = seq(0,100,0.1)
bhat                = glm(buying~income,family=binomial(link="probit"),data=organic)
bhat_ols            = lm(buying~income,data=organic)
z                   = bhat$coefficients[1]+bhat$coefficients[2]*income
logit_cdf           = exp(z)/(1+exp(z))
plot(organic,xlim=c(0,100))
abline(bhat_ols)
lines(income,logit_cdf,type="l")
```

# Coefficicent Estimates
## Estimation with R
Coefficient estimates using the built-in R command:
```{r,results=FALSE,warning=FALSE,message=FALSE,error=FALSE}
bhatglm = glm(buying~income,
              family=binomial(link="logit"),
              data=organic)
library(mfx)
bhatmfx = logitmfx(buying~income,data=organic)
```

Obtaining summary from `bhatmfx`
```{r,results=FALSE}
summary(bhatmfx$fit)
```

## Base Results
\tiny
```{r,echo=FALSE}
summary(bhatglm)
```
\normalsize 

## Results from `mfx`
\tiny
```{r,echo=FALSE}
summary(bhatmfx$fit)
```
\normalsize

# Marginal Effects
## Marginal Effects with `mfx` package
Advantage of [mfx](https://cran.r-project.org/web/packages/mfx/index.html) package: Estimation of marginal effects

```{r}
bhatmfx$mfxest
```

Important note:
    
- Marginal effects are estimated at the mean of the independent variable(s)!

# Predicted Probabilities
## Fitted Values in a Binary Choice Model
Example: 
        
- What are the predicted probabilities of a person purchasing organic given their annual income (in \$ 1,000) of 25, 50, and 75?
        
Solution in R:
```{r,results=FALSE}
datablock = data.frame(income=c(25,50,75))
test = predict(bhatglm,newdata=datablock,type="response")
```

## Probit Model
Very similar results compared to Logit:
```{r}
bhatmfx = probitmfx(buying~income,data=organic)
bhatmfx$mfxest
```

# Additional Example
## Food Purchases `fpdata`
Food purchases data:

- `strawberries_org`: Frequency of strawberry purchases per month
- `tomatoes_org`: Frequency of strawberry purchases per month
- `age`: Age of the respondent
- `kidsunder12`: Presence of kids under the age of 12
- `rootsurban`: Urban (as opposed to rural) upbringing of respondent
- `education`: Education level
- `income`: Income

## Data Preparation and Estimation
```{r}
fpdata$strawberriesorg  = ifelse(fpdata$strawberriesorg==0,0,1)
fpdata$tomatoesorg      = ifelse(fpdata$tomatoesorg==0,0,1)
```


```{r}
bhats = glm(strawberriesorg~age+kidsunder12+rootsurban+
            education+income,
            family=binomial(link="logit"),
            data=fpdata)
bhatt = glm(tomatoesorg~age+kidsunder12+rootsurban+
            education+income,
            family=binomial(link="logit"),
            data=fpdata)
```

## Results Strawberries
\tiny
```{r,echo=FALSE}
summary(bhats)
```
\normalsize

## Results Tomatoes
\tiny
```{r,echo=FALSE}
summary(bhatt)
```
\normalsize

## Additional Questions
For the strawberries and tomatoes regression, do the following:

- Calculate the marginal effects of all independent variables
- Calculate the predicted probability for each observation
